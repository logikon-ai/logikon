{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logikon.backends.chat_models_with_grammar import create_logits_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "\"HUGGINGFACEHUB_API_TOKEN\" in os.environ or print(\"Please set HUGGINGFACEHUB_API_TOKEN in .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    #\"model_id\": \"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    #\"inference_server_url\": \"https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    \"model_id\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    \"inference_server_url\": \"https://px0zqc1h7zw38b0b.us-east-1.aws.endpoints.huggingface.cloud\",\n",
    "    \"llm_backend\": \"HFChat\",\n",
    "    \"api_key\": os.environ.get('HUGGINGFACEHUB_API_TOKEN'),\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "hf_chat = create_logits_model(**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "res = await hf_chat.get_labelprobs(\n",
    "    [HumanMessage(content=\"What is the capital of Canada?\\n(A) Paris\\n(B) Lyon\\n(C) Quebec\")],\n",
    "    labels=[\"A\", \"B\", \"C\"],\n",
    "    top_logprobs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.043252036708846336, 'B': 0.11174987599215074, 'C': 0.8449980872990028}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ontario', 'London']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REGEX\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the capital of {country}?\"\n",
    ")\n",
    "regex = r\"(Washington|Ontario|London)\"\n",
    "gen_args = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"regex\": regex,\n",
    "}\n",
    "chain = (\n",
    "    prompt\n",
    "    | hf_chat.bind(**gen_args).with_retry()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "# fmt: on\n",
    "\n",
    "inputs = [\n",
    "    {\"country\": \"Canada\"},\n",
    "    {\"country\": \"France\"},\n",
    "]\n",
    "\n",
    "results = chain.batch(inputs)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'country': {'title': 'Country', 'type': 'string'}, 'capital': {'title': 'Capital', 'type': 'string'}}, 'required': ['country', 'capital'], 'title': 'CapitalModel', 'type': 'object'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['{  \\n  \"capital\": \"Paris\"\\n , \\n  \"country\": \"France\"\\n}',\n",
       " '{  \\n  \"capital\": \"Paris\"\\n , \\n  \"country\": \"France\"\\n}']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class CapitalModel(BaseModel):\n",
    "    country: str\n",
    "    capital: str    \n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the capital of {country}?\"\n",
    ")\n",
    "guided_json = CapitalModel.model_json_schema()\n",
    "print(guided_json)\n",
    "gen_args = {\"temperature\": 0.4, \"json_schema\": guided_json}\n",
    "chain = (\n",
    "    prompt\n",
    "    | hf_chat.bind(**gen_args).with_retry()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "# fmt: on\n",
    "\n",
    "inputs = [\n",
    "    {\"country\": \"Canada\"},\n",
    "    {\"country\": \"France\"},\n",
    "]\n",
    "\n",
    "results = chain.batch(inputs)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logikon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
